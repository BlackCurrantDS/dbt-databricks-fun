{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb924e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook: Download artifacts for latest run of a given task of THIS job\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "# PARAMETERS\n",
    "# ----------\n",
    "dbutils.widgets.text(\"TASK_KEY\", \"\")               # task_key (task name) within this job\n",
    "dbutils.widgets.text(\"SOURCE_PATH\", \"\")            # subfolder inside artifacts, empty for root\n",
    "dbutils.widgets.text(\"DEST_PATH\", \"\")   # local/DBFS dest on this cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_KEY = dbutils.widgets.get(\"TASK_KEY\").strip()\n",
    "SOURCE_PATH = dbutils.widgets.get(\"SOURCE_PATH\").strip()\n",
    "DEST_PATH = dbutils.widgets.get(\"DEST_PATH\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a36381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(cmd: str) -> str:\n",
    "    \"\"\"Run a shell command and return stdout; raise on error.\"\"\"\n",
    "    print(f\"Executing: {cmd}\")\n",
    "    result = subprocess.run(\n",
    "        cmd,\n",
    "        shell=True,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(\n",
    "            f\"Command failed ({result.returncode}).\\n\"\n",
    "            f\"STDOUT:\\n{result.stdout}\\n\\nSTDERR:\\n{result.stderr}\"\n",
    "        )\n",
    "    return result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a78ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configure CLI to use Jobs API 2.1\n",
    "out_config = run_cmd(\"databricks jobs configure --version=2.1\")\n",
    "print(out_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get JOB_ID of *this* notebook's job\n",
    "# --------------------------------------\n",
    "JOB_ID = dbutils.notebook().getContext().toJson()['job_id']\n",
    "JOB_ID = dbutils.notebook.entry_point.getDbutils().notebook().getContext().toJson() \n",
    "print(f\"Current job id (JOB_ID) = {JOB_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Databricks SDK\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed21970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client using the job's identity (service principal / compute identity)\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Get run info (Jobs API 2.1)\n",
    "run = w.jobs.get_run(run_id=int(JOB_ID))\n",
    "\n",
    "# `run` is a JobsGetRunResponse; `run.tasks` is a list of RunTask instances\n",
    "tasks = run.tasks or []\n",
    "\n",
    "# Pretty-print equivalent to `jq .tasks`\n",
    "print(json.dumps([t.as_dict() for t in tasks], indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
