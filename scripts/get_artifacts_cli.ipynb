{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb924e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook: Download artifacts for latest run of a given task of THIS job\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "# PARAMETERS\n",
    "# ----------\n",
    "dbutils.widgets.text(\"TASK_KEY\", \"\")               # task_key (task name) within this job\n",
    "dbutils.widgets.text(\"SOURCE_PATH\", \"\")            # subfolder inside artifacts, empty for root\n",
    "dbutils.widgets.text(\"DEST_PATH\", \"\")   # local/DBFS dest on this cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_KEY = dbutils.widgets.get(\"TASK_KEY\").strip()\n",
    "SOURCE_PATH = dbutils.widgets.get(\"SOURCE_PATH\").strip()\n",
    "DEST_PATH = dbutils.widgets.get(\"DEST_PATH\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f08b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TASK_KEY:\n",
    "    raise ValueError(\"TASK_KEY widget must be provided (task_key within the job).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbruntime.databricks_repl_context as repl_ctx\n",
    "import subprocess\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a36381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(cmd: str) -> str:\n",
    "    \"\"\"Run a shell command and return stdout as string. Raises on non-zero exit.\"\"\"\n",
    "    print(f\"Executing: {cmd}\")\n",
    "    result = subprocess.run(\n",
    "        cmd,\n",
    "        shell=True,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True,\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(\n",
    "            f\"Command failed ({result.returncode}).\\n\"\n",
    "            f\"STDOUT:\\n{result.stdout}\\n\\nSTDERR:\\n{result.stderr}\"\n",
    "        )\n",
    "    return result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a78ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(path: str):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get JOB_ID of *this* notebook's job\n",
    "# --------------------------------------\n",
    "ctx = repl_ctx.get_context()\n",
    "if not ctx.jobId().isDefined():\n",
    "    raise RuntimeError(\"This notebook is not running inside a job; no jobId is available.\")\n",
    "\n",
    "JOB_ID = ctx.jobId().get()\n",
    "print(f\"Current job id (JOB_ID) = {JOB_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29370ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Ensure Jobs API 2.1 for CLI\n",
    "# ------------------------------\n",
    "run_cmd(\"databricks jobs configure --version=2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f040792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Find latest JOB_RUN_ID of this JOB_ID that has TASK_KEY\n",
    "# ----------------------------------------------------------\n",
    "# Command:\n",
    "#   databricks jobs list-runs --job-id JOB_ID --limit 50 --output JSON\n",
    "# Then jq:\n",
    "#   filter runs whose .tasks contains TASK_KEY, sort by start_time desc, pick first .run_id\n",
    "\n",
    "jq_filter_runs = rf'''\n",
    "[\n",
    "  .runs[]\n",
    "  | select(any(.tasks[]?; .task_key == \"{TASK_KEY}\"))\n",
    "]\n",
    "| sort_by(.start_time) | reverse\n",
    "| .[0].run_id\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f990b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_list_runs = (\n",
    "    f'databricks jobs list-runs --job-id \"{JOB_ID}\" --limit 50 --output JSON '\n",
    "    f'| jq -r \\'{jq_filter_runs}\\''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run_id_output = run_cmd(cmd_list_runs).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not job_run_id_output or job_run_id_output == \"null\":\n",
    "    raise RuntimeError(\n",
    "        f\"No runs found for job_id={JOB_ID} that contain task_key='{TASK_KEY}'.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4211fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_RUN_ID = job_run_id_output\n",
    "print(f\"Latest JOB_RUN_ID={JOB_RUN_ID} for JOB_ID={JOB_ID}, TASK_KEY={TASK_KEY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8995240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Get TASK_RUN_ID for that JOB_RUN_ID and TASK_KEY\n",
    "# ---------------------------------------------------\n",
    "# Command:\n",
    "#   databricks runs get --run-id JOB_RUN_ID\n",
    "# Then jq:\n",
    "#   .tasks[] | select(.task_key==\"TASK_KEY\") | .run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab350304",
   "metadata": {},
   "outputs": [],
   "source": [
    "jq_filter_task_run = f'.tasks[] | select(.task_key == \"{TASK_KEY}\") | .run_id'\n",
    "cmd_get_task_run_id = (\n",
    "    f'databricks runs get --run-id \"{JOB_RUN_ID}\" '\n",
    "    f'| jq -r \\'{jq_filter_task_run}\\''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e87e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task_run_id_output = run_cmd(cmd_get_task_run_id).strip()\n",
    "if not task_run_id_output or task_run_id_output == \"null\":\n",
    "    raise RuntimeError(\n",
    "        f\"No task with task_key='{TASK_KEY}' found in job run {JOB_RUN_ID}.\"\n",
    "    )\n",
    "\n",
    "TASK_RUN_ID = task_run_id_output\n",
    "print(\n",
    "    f\"TASK_RUN_ID={TASK_RUN_ID} for JOB_ID={JOB_ID}, \"\n",
    "    f\"JOB_RUN_ID={JOB_RUN_ID}, TASK_KEY={TASK_KEY}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ebd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Download artifacts for that TASK_RUN_ID\n",
    "# ------------------------------------------\n",
    "ensure_dir(DEST_PATH)\n",
    "\n",
    "base_cmd = (\n",
    "    f'databricks runs download-artifacts '\n",
    "    f'--run-id \"{TASK_RUN_ID}\" '\n",
    "    f'--dest \"{DEST_PATH}\"'\n",
    ")\n",
    "if SOURCE_PATH:\n",
    "    base_cmd += f' --path \"{SOURCE_PATH}\"'\n",
    "\n",
    "print(\"Downloading artifacts:\")\n",
    "print(f\"  job_id      = {JOB_ID}\")\n",
    "print(f\"  job_run_id  = {JOB_RUN_ID}\")\n",
    "print(f\"  task_run_id = {TASK_RUN_ID}\")\n",
    "print(f\"  task_key    = {TASK_KEY}\")\n",
    "print(f\"  source path = '{SOURCE_PATH or '/'}'\")\n",
    "print(f\"  dest path   = '{DEST_PATH}'\")\n",
    "\n",
    "download_output = run_cmd(base_cmd)\n",
    "print(download_output)\n",
    "\n",
    "print(\"Artifact download complete.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
